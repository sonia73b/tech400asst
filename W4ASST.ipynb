{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonia73b/tech400asst/blob/main/W4ASST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCNjo-6S8Mog"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhoncnR3sHp6"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function\n",
        "def preprocess(text):\n",
        "    return re.findall(r'\\b\\w+\\b', text.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVxrTKkAsHp6"
      },
      "outputs": [],
      "source": [
        "# Load documents\n",
        "def load_documents(folder_path):\n",
        "    docs = {}\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.txt'):\n",
        "            with open(os.path.join(folder_path, filename), 'r') as file:\n",
        "                docs[filename] = preprocess(file.read())\n",
        "    return docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USuiA7fZsHp6"
      },
      "outputs": [],
      "source": [
        "# Load queries\n",
        "def load_queries(query_file_path):\n",
        "    with open(query_file_path, 'r') as file:\n",
        "        return [line.strip() for line in file.readlines()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8J9I8qv_sHp7"
      },
      "outputs": [],
      "source": [
        "def compute_statistics(docs):\n",
        "    term_freq = defaultdict(lambda: defaultdict(int))\n",
        "    term_doc_freq = defaultdict(int)\n",
        "    collection_freq = defaultdict(int) # Total times a term appears in the whole corpus\n",
        "    doc_lengths = {} # Length of each document\n",
        "    total_corpus_len = 0\n",
        "\n",
        "    for doc_id, tokens in docs.items():\n",
        "        doc_lengths[doc_id] = len(tokens)\n",
        "        total_corpus_len += len(tokens)\n",
        "\n",
        "        # Count terms\n",
        "        unique_tokens = set(tokens)\n",
        "        for token in tokens:\n",
        "            term_freq[doc_id][token] += 1\n",
        "            collection_freq[token] += 1\n",
        "\n",
        "        for token in unique_tokens:\n",
        "            term_doc_freq[token] += 1\n",
        "\n",
        "    num_docs = len(docs)\n",
        "    avg_doc_length = total_corpus_len / num_docs if num_docs > 0 else 0\n",
        "\n",
        "    return term_freq, term_doc_freq, collection_freq, doc_lengths, avg_doc_length, total_corpus_len, num_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8K_Aef3ssHp8"
      },
      "outputs": [],
      "source": [
        "def compute_bm25_score(query, doc_id, docs, term_freq, term_doc_freq, doc_lengths, avg_doc_length, num_docs):\n",
        "    k1 = 1.2\n",
        "    b = 0.75\n",
        "    score = 0.0\n",
        "    doc_len = doc_lengths[doc_id]\n",
        "\n",
        "    for term in query:\n",
        "        if term not in docs[doc_id]:\n",
        "            continue\n",
        "\n",
        "        tf = term_freq[doc_id][term]\n",
        "        df = term_doc_freq.get(term, 0)\n",
        "\n",
        "        # Inverse Document Frequency (IDF)\n",
        "        idf = math.log(1 + (num_docs - df + 0.5) / (df + 0.5))\n",
        "\n",
        "        # Term Frequency saturation\n",
        "        numerator = tf * (k1 + 1)\n",
        "        denominator = tf + k1 * (1 - b + b * (doc_len / avg_doc_length))\n",
        "\n",
        "        score += idf * (numerator / denominator)\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Qq-iDavCsHp8"
      },
      "outputs": [],
      "source": [
        "def compute_lm_jm_score(query, doc_id, docs, term_freq, collection_freq, doc_lengths, total_corpus_len):\n",
        "    lambda_param = 0.7  # Smoothing parameter\n",
        "    score = 0.0\n",
        "    doc_len = doc_lengths[doc_id]\n",
        "\n",
        "    for term in query:\n",
        "        # P(t|D): Probability of term in document\n",
        "        tf = term_freq[doc_id].get(term, 0)\n",
        "        p_t_d = tf / doc_len if doc_len > 0 else 0\n",
        "\n",
        "        # P(t|C): Probability of term in collection\n",
        "        cf = collection_freq.get(term, 0)\n",
        "        p_t_c = cf / total_corpus_len if total_corpus_len > 0 else 0\n",
        "\n",
        "        # JM Smoothing: Mix the two probabilities\n",
        "        smoothed_prob = (lambda_param * p_t_d) + ((1 - lambda_param) * p_t_c)\n",
        "\n",
        "        # Log probability to avoid underflow\n",
        "        if smoothed_prob > 0:\n",
        "            score += math.log(smoothed_prob)\n",
        "        else:\n",
        "            score += -20 # Penalty for zero probability\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gpe5g_aNsHp9"
      },
      "outputs": [],
      "source": [
        "def retrieve_documents_and_result(trump_speeches_path, query_file_path, output_file_name):\n",
        "    docs = load_documents(trump_speeches_path)\n",
        "    queries = load_queries(query_file_path)\n",
        "\n",
        "    # UNPACKING FIXED: Now accepting all 7 values returned by compute_statistics\n",
        "    term_freq, term_doc_freq, collection_freq, doc_lengths, avg_doc_len, total_corpus_len, num_docs = compute_statistics(docs)\n",
        "\n",
        "    with open(output_file_name, 'w') as results_file:\n",
        "        for query in queries:\n",
        "            query_terms = preprocess(query)\n",
        "            if not query_terms:\n",
        "                continue\n",
        "\n",
        "            # Calculate BM25 Scores\n",
        "            bm25_scores = []\n",
        "            for doc_id in docs:\n",
        "                score = compute_bm25_score(query_terms, doc_id, docs, term_freq, term_doc_freq, doc_lengths, avg_doc_len, num_docs)\n",
        "                bm25_scores.append((doc_id, score))\n",
        "            bm25_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            # Calculate LM-JM Scores\n",
        "            lm_scores = []\n",
        "            for doc_id in docs:\n",
        "                score = compute_lm_jm_score(query_terms, doc_id, docs, term_freq, collection_freq, doc_lengths, total_corpus_len)\n",
        "                lm_scores.append((doc_id, score))\n",
        "            lm_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            # Write Combined Results\n",
        "            results_file.write(f\"Query: {query}\\n\")\n",
        "            results_file.write(\"-\" * 40 + \"\\n\")\n",
        "\n",
        "            results_file.write(\"Results (Okapi BM25):\\n\")\n",
        "            for doc_id, score in bm25_scores:\n",
        "                results_file.write(f\"  Document: {doc_id}, Score: {score:.4f}\\n\")\n",
        "\n",
        "            results_file.write(\"\\nResults (LM with Jelinek-Mercer):\\n\")\n",
        "            for doc_id, score in lm_scores:\n",
        "                results_file.write(f\"  Document: {doc_id}, Score: {score:.4f}\\n\")\n",
        "\n",
        "            results_file.write(\"\\n\" + \"=\"*40 + \"\\n\\n\")\n",
        "\n",
        "    print(f\"Results written to {output_file_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23yWtRJ0sHp9",
        "outputId": "e13017ce-9a2c-4c8c-acaa-363a9a896e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results written to resultsBM25.txt\n"
          ]
        }
      ],
      "source": [
        "# Main function\n",
        "def main():\n",
        "    trump_speeches_path = '/content/drive/MyDrive/TECH400TXTFILES'\n",
        "    query_file_path = '/content/drive/MyDrive/TECH400TXTFILES/queries1.txt'\n",
        "    output_file_name = 'resultsBM25.txt'\n",
        "    retrieve_documents_and_result(trump_speeches_path, query_file_path, output_file_name)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxxG---xseV6",
        "outputId": "4662a584-455b-4d85-9c3d-e886d6eb7941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSa5ABslsHp-"
      },
      "source": [
        "## **Sample of Retrieval Results**\n",
        "\n",
        "| Query | Top Doc (BM25) | Score (BM25) | Top Doc (LM-JM) | Score (LM-JM) |\n",
        "| :--- | :--- | :--- | :--- | :--- |\n",
        "| \"to\" | speech_30.txt | 0.0192 | speech_13.txt | -3.1941 |\n",
        "| \"america strong\" | speech_2.txt | 0.5943 | speech_13.txt | -11.6011 |\n",
        "| \"to bring us\" | speech_36.txt | 0.4018 | speech_3.txt | -15.7044 |\n",
        "| \"white\" | speech_49.txt | 0.8017 | speech_49.txt | -6.6489 |\n",
        "| \"future i\" | speech_20.txt | 0.6607 | speech_11.txt | -9.9884 |\n",
        "| \"victory and\" | speech_27.txt | 1.5360 | speech_27.txt | -9.7200 |"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}